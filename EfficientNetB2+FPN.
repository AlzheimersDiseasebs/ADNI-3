import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, Conv2D, UpSampling2D, Add
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.applications import EfficientNetB2
from tensorflow.keras.models import Model
from tensorflow.keras.metrics import AUC, BinaryAccuracy, Precision, Recall
import matplotlib.pyplot as plt

# Veri setini yükleyin
images = np.load("resized_images_MCIEMCI_elle.npy")
labels = np.load("data_label_MCIEMCI_elle.npy")

# Veriyi (224, 224, 3) boyutlarına yeniden şekillendirin
images = np.array([np.resize(img, (224, 224, 3)) for img in images])

# Etiketleri kategorik formata dönüştürün
labels = to_categorical(labels - 1, 5)

# Veriyi standartlaştırın (normalize edin)
images = images.astype('float32') / 255.0  # Görüntüleri [0, 1] aralığına normalize edin

# 10 katlı çapraz doğrulama için bölmek
kfold = StratifiedShuffleSplit(n_splits=10, random_state=42)
fold_accuracies = []

# Katman isimlerini kontrol etme
def print_model_layers(model):
    for i, layer in enumerate(model.layers):
        print(f"Layer {i}: {layer.name}")

# FPN Bloğu
def build_fpn_feature_pyramid(base_model):
    # Retrieve the feature maps from the base model
    x1 = base_model.get_layer('block1a_activation').output
    x2 = base_model.get_layer('block2a_activation').output
    x3 = base_model.get_layer('block3a_activation').output
    x4 = base_model.get_layer('block4a_activation').output
    x5 = base_model.get_layer('block6a_activation').output

    # Define the FPN blocks
    p5 = Conv2D(256, (1, 1), padding='same', activation='relu')(x5)
    p4 = Conv2D(256, (1, 1), padding='same', activation='relu')(x4)
    p4 = UpSampling2D(size=(2, 2))(p4)
    p4 = tf.image.resize(p4, size=(tf.shape(p5)[1], tf.shape(p5)[2]))  # p5'in boyutlarına yeniden ölçekleme
    p4 = Add()([p4, p5])

    p3 = Conv2D(256, (1, 1), padding='same', activation='relu')(x3)
    p3 = UpSampling2D(size=(2, 2))(p3)
    p3 = tf.image.resize(p3, size=(tf.shape(p4)[1], tf.shape(p4)[2]))  # p4'ün boyutlarına yeniden ölçekleme
    p3 = Add()([p3, p4])

    p2 = Conv2D(256, (1, 1), padding='same', activation='relu')(x2)
    p2 = UpSampling2D(size=(2, 2))(p2)
    p2 = tf.image.resize(p2, size=(tf.shape(p3)[1], tf.shape(p3)[2]))  # p3'ün boyutlarına yeniden ölçekleme
    p2 = Add()([p2, p3])

    p1 = Conv2D(256, (1, 1), padding='same', activation='relu')(x1)
    p1 = UpSampling2D(size=(2, 2))(p1)
    p1 = tf.image.resize(p1, size=(tf.shape(p2)[1], tf.shape(p2)[2]))  # p2'nin boyutlarına yeniden ölçekleme
    p1 = Add()([p1, p2])

    return p1

# 10 katlı çapraz doğrulama döngüsü
for train_index, test_index in kfold.split(images, np.argmax(labels, axis=1)):
    X_train, X_test = images[train_index], images[test_index]
    y_train, y_test = labels[train_index], labels[test_index]

    # EfficientNetB2 modelini yükleyin
    efficientNet = EfficientNetB2(weights=None, include_top=False, input_shape=(224, 224, 3))

    # FPN özelliğini oluştur
    fpn_features = build_fpn_feature_pyramid(efficientNet)

    # FPN özelliklerini modelin geri kalanına bağlayın
    x = GlobalAveragePooling2D()(fpn_features)
    x = Dropout(rate=0.5)(x)
    x = Dense(5, activation='softmax')(x)  # 5 sınıf olduğunu varsayalım
    model = Model(inputs=efficientNet.input, outputs=x)

    # Modeli derleyin
    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[AUC(), BinaryAccuracy(), Precision(), Recall()])

    # Eğitim sırasında accuracy değerlerini kaydetmek için bir callback fonksiyonu oluşturun
    class AccuracyCallback(tf.keras.callbacks.Callback):
        def __init__(self):
            super(AccuracyCallback, self).__init__()
            self.train_accuracies = []

        def on_epoch_end(self, epoch, logs=None):
            train_acc = logs.get('binary_accuracy')
            print(f'Training Accuracy for Epoch {epoch + 1}: {train_acc}')
            self.train_accuracies.append(train_acc)

    accuracy_callback = AccuracyCallback()

    # Modeli eğitin
    history = model.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_test, y_test), callbacks=[accuracy_callback])

    fold_accuracies.append(accuracy_callback.train_accuracies)  # Her bir kategori için accuracy değerlerini ayrı ayrı kaydedin

# Tüm katmanların accuracy değerlerini birleştirin
all_accuracies = np.mean(np.array(fold_accuracies), axis=0)

# Eğitim sırasında accuracy değerlerini gösteren bir grafik oluşturun
plt.plot(range(1, len(all_accuracies) + 1), all_accuracies, label='Average Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy Over Epochs for All Folds')
plt.legend()
plt.show()

# Her bir fold için accuracy değerlerini gösteren bir grafik oluşturun
for i, fold_accuracy in zip(range(1, 11), fold_accuracies):
    plt.plot(range(1, len(fold_accuracy) + 1), fold_accuracy, label=f'Fold {i}')

plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy Over Epochs for All Folds')
plt.legend()
plt.show()



